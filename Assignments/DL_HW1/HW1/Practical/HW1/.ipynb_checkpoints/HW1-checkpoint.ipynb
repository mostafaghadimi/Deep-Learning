{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#  CE-40959: Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Homework1: Preliminaries & Numpy (65pts)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can run cells by hitting `Shift` + `Enter`. <br/>\n",
    "We higly recommend you to read each line of code carefully and try to unserstand what it exactly does. You may want to use the techniques mentioned in this notebook in your next assignments.<br/>\n",
    "Please review `Numpy Tutorial` notebook (materials of the first TA class) before coming to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Deadline:   2 Esfand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import numpy as np\n",
    "import os\n",
    "from svm import SVM\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0) # set default size of plots\n",
    "\n",
    "# The following two lines let us reload external modules in the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Problem 1. Computational Graph (13pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this problem, you have to compute the gradient of $out$ which will be computed in function `gradients` with respect to $x$, $y$, $z$, $w$, $t$ (i.e., $\\large{\\frac{\\partial{out}}{\\partial{x}}}$, $\\large{\\frac{\\partial{out}}{\\partial{y}}}$, $\\large{\\frac{\\partial{out}}{\\partial{z}}}$, $\\large{\\frac{\\partial{out}}{\\partial{w}}}$, $\\large{\\frac{\\partial{out}}{\\partial{t}}}$) using the chain rule and save them in $grad\\_x$, $grad\\_y$, $grad\\_z$, $grad\\_w$, $grad\\_t$ and return them.\n",
    "\n",
    "Here is the computations that should be done by `gradients` in a mathematical form:\n",
    "\n",
    "\\begin{equation}\n",
    "z = matmul(x, I - y) \\\\\n",
    "\\\\\n",
    "w = x * x \\\\\n",
    "\\\\\n",
    "t = -\\frac{1}{log(w + abs(z))} \\\\\n",
    "out = \\text{sum  of  the elements  of}\\;t\\\\\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "Note: $\\mathbf I$ in the first equation is the Identity matrix. $\\mathbf{matmul}$ is matrix multiplication. $\\mathbf *$ is elementwise multiplication. $\\mathbf{log}$ is to the base of $\\mathbf{e}$. $\\mathbf{abs}$ in the third equation is the (elementwise) absolute value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def gradients(x, y):\n",
    "    \"\"\"\n",
    "    x: a numpy 2d-array with shape (N, M)\n",
    "    y: a numpy 2-d array with shape (M, M)\n",
    "    ouput: grad_x, grad_y, grad_z, grad_w, grad_t which are numpy ndarrays\n",
    "    \"\"\"\n",
    "    z, w, t, out = [None] * 4\n",
    "    grad_x, grad_y, grad_z, grad_w, grad_t = [None] * 5\n",
    "    ####################################################################################\n",
    "    # TODO: 1) build the computational graph specified by the equations above and save #\n",
    "    #          the values in z, w, t, out.                                             #\n",
    "    #       2) compute the gradients of out with respect to x, y, z, w, t and save     #\n",
    "    #          them in grad_x, grad_y, grad_z, grad_w, grad_t respectively.            #\n",
    "    #          Hint: Note that the gradient of a scalar with respect to a matix M has  #\n",
    "    #          always the same shape as M.                                             #\n",
    "    ####################################################################################\n",
    "\n",
    "    \n",
    "    \n",
    "    n, m = x.shape\n",
    "    \n",
    "    z = np.matmul(x, np.eye(m) - y)\n",
    "    w = np.multiply(x, x)\n",
    "    out = np.divide(-1, np.log(w + np.abs(z)))\n",
    "    \n",
    "    grad_x = np.gradient(out, x)\n",
    "    grad_y = np.gradient(out, y)\n",
    "    grad_z = np.gradient(out, z)\n",
    "    grad_w = np.gradient(out, w)\n",
    "    grad_t = np.gradient(out, t)\n",
    "    \n",
    "    ####################################################################################\n",
    "    #                                 END OF YOUR CODE                                 #\n",
    "    ####################################################################################\n",
    "    return grad_x, grad_y, grad_z, grad_w, grad_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's check if you have correctly computed gradients. You have to get small values as the ouput. The largest order of ours is 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[0.37454012 0.95071431 0.73199394 0.59865848]\n",
      " [0.15601864 0.15599452 0.05808361 0.86617615]\n",
      " [0.60111501 0.70807258 0.02058449 0.96990985]]\n",
      "Y:\n",
      " [[0.83244264 0.21233911 0.18182497 0.18340451]\n",
      " [0.30424224 0.52475643 0.43194502 0.29122914]\n",
      " [0.61185289 0.13949386 0.29214465 0.36636184]\n",
      " [0.45606998 0.78517596 0.19967378 0.51423444]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid number of arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9ac22eae56f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtest_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-9ac22eae56f4>\u001b[0m in \u001b[0;36mtest_gradients\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgrad_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     correct_grad_x = [[ 98.53486691, 178.15428636, 101.50170543, 140.87675175],\n",
      "\u001b[0;32m<ipython-input-19-175444d10ca1>\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mgrad_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mgrad_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mgrad_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(f, *varargs, **kwargs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiffx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid number of arguments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0medge_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'edge_order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid number of arguments"
     ]
    }
   ],
   "source": [
    "def test_gradients():\n",
    "    np.random.seed(42)\n",
    "    x = np.random.rand(3, 4)\n",
    "    y = np.random.rand(4, 4)\n",
    "    \n",
    "    grad_x, grad_y, grad_z, grad_w, grad_t = gradients(x, y)\n",
    "    \n",
    "    correct_grad_x = [[ 98.53486691, 178.15428636, 101.50170543, 140.87675175],\n",
    "                      [-29.11111973, -50.35135437, -61.51644322, 396.80894273],\n",
    "                      [260.24004063, 319.32608058, 119.95375672, 653.73810858]]\n",
    "    \n",
    "    correct_grad_y = [[ 175.60725449,  221.87847075,    6.64595782, -101.40000624],\n",
    "                      [ 273.07420644,  308.49236288,   11.29541668, -109.51168111],\n",
    "                      [  99.83039306,   74.98883877,    5.30629792,   -5.51204454],\n",
    "                      [ 284.95194676,  363.24817383,   11.92286996, -270.95042005]]\n",
    "    \n",
    "    correct_grad_z = [[-130.17216803,  -93.01792945,   -6.91408473,   -9.96854119],\n",
    "                      [  -3.81552552,   -9.39164072,   -2.01597763,  174.60396305],\n",
    "                      [-210.03844462, -308.71671769,   -6.22480814,  129.57944883]]\n",
    "    \n",
    "    correct_grad_w = [[130.17216803,  93.01792945,   6.91408473,   9.96854119],\n",
    "                      [  3.81552552,   9.39164072,   2.01597763, 174.60396305],\n",
    "                      [210.03844462, 308.71671769,   6.22480814, 129.57944883]]\n",
    "    \n",
    "    correct_grad_t = [[1., 1., 1., 1.],\n",
    "                      [1., 1., 1., 1.],\n",
    "                      [1., 1., 1., 1.]]\n",
    "    \n",
    "    \n",
    "    print('relative error of grad_x:', np.linalg.norm(grad_x - correct_grad_x))\n",
    "    print('relative error of grad_y:', np.linalg.norm(grad_y - correct_grad_y))\n",
    "    print('relative error of grad_z:', np.linalg.norm(grad_z - correct_grad_z))\n",
    "    print('relative error of grad_w:', np.linalg.norm(grad_w - correct_grad_w))\n",
    "    print('relative error of grad_t:', np.linalg.norm(grad_t - correct_grad_t))\n",
    "    \n",
    "\n",
    "test_gradients()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Problem 2. Shy away from for loops! (12pts)\n",
    "Suppose that we have a matrix called $X$ which is a numpy 2d-array with shape $(N_1, D)$. This matrix has $N_1$ rows and the $i$-th row represents a $D-$dimensional vector such as $X_i$ (called an instance). There is also another matrix named $Y$ with the shape $(N_2, D)$. Note that $N_1$ is not necessarily equal to $N_2$. Our goal is to compute the following value for each instance in the first matrix and each instance in the second matrix:\n",
    "\n",
    "\\begin{equation}\n",
    " \\\\\n",
    "V(X_i, Y_j) = {\\sum_{k=1}^{D}{(x_k - y_k)^3}}\n",
    "\\end{equation}\n",
    "\n",
    "where $X_i = [x_1, x_2, ...., x_D]$ and $Y_j = [y_1, y_2, ..., y_D]$ are the $i$-th and $j$-th instance in the first and second matrix respectively.\n",
    "\n",
    "We want to compute a matrix `V` whose $(i, j)$-th entry is $V(X_i, Y_j)$. Complete the code of following functions to do this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def values_with_for_loop(X, Y):\n",
    "    \"\"\"\n",
    "    X: numpy 2d-array with shape (N1, D)\n",
    "    Y: numpy 2d-array with shape (N2, D)\n",
    "    V: Values matrix which should be a 2d-array with shape (N1, N2)\n",
    "    \"\"\"\n",
    "    V = None\n",
    "    #####################################################################################\n",
    "    # TODO:                                                                             #\n",
    "    # Compute V(X_i, Y_j) for each i and j and store it in V[i, j]. You are free to use #\n",
    "    # for loops (preferably one or two for loops as more than that might run            #\n",
    "    # prohibitively slowly!) in your implementation. You are free to use any Numpy      #\n",
    "    # function you want.                                                                #\n",
    "    #####################################################################################\n",
    "    pass\n",
    "    #####################################################################################\n",
    "    #                                 END OF YOUR CODE                                  #\n",
    "    #####################################################################################\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's test your implementation of `values_with_for_loop` with the following function. You have to witness a small value as the ouput. we get an ouput of the order of 1e-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def test_values_with_for_loop():\n",
    "    X = np.random.randn(10, 8)\n",
    "    Y = np.random.randn(8, 8)\n",
    "    \n",
    "    out_correct = np.asarray([[  8.765334,    20.010048,    18.260977,    43.856083,   -14.216753,\n",
    "                                 29.56002,     29.146101,    51.783203  ],\n",
    "                              [ -28.092327,    -7.90782,     -1.9417393,  -19.624632,   -33.951344,\n",
    "                                -74.167725,   -19.233025,   -34.774654  ],\n",
    "                              [ -9.0146055,   -4.3492904,   19.111053,   -19.567537,   -23.901215,\n",
    "                                -29.252842,   -13.360028,    -6.035372  ],\n",
    "                              [ -17.440336,    34.22961,     17.316256,   -19.815384,   -17.601694,\n",
    "                                -15.11916,     -0.2324852,   -2.339958  ],\n",
    "                              [ -16.793228,   -13.687567,    -2.0563402,  -13.523884,   -61.872227,\n",
    "                                -71.84135,     -3.8474934,  -34.78388   ],\n",
    "                              [ -5.693445,    15.429427,     6.4837265,   -8.542441,   -18.958473,\n",
    "                                -29.938059,     1.6775647,   -7.4752984 ],\n",
    "                              [ -9.28221,      3.8474603,    1.0413681,   12.016386,   -70.26817,\n",
    "                                 4.750604,    11.754794,    16.634857  ],\n",
    "                              [ -10.45044,     -0.9044826,    0.48504904,  -5.3853908,  -39.49779,\n",
    "                                -6.7880898,  -14.213244,     4.442503  ],\n",
    "                              [  5.0958433,   31.653896,    22.115992,    10.347621,    -0.3687537,\n",
    "                                 11.317683,    14.432735,    21.924892  ],\n",
    "                              [ -76.88806,    -18.312935,   -12.917151,   -89.0802,     -35.949398,\n",
    "                                -56.66989,    -34.12826,    -34.17443   ]])\n",
    "    out = values_with_for_loop(X, Y)\n",
    "    print('relative error of values:', np.linalg.norm(out - out_correct))\n",
    "    \n",
    "test_values_with_for_loop()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, let's make it more challenging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def values_without_for_loop(X, Y):\n",
    "    V = None\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Compute the matrix V WITHOUT for loops this time!                            #\n",
    "    # Note that if you use for loops you will get no points.                       #  \n",
    "    # Hint: Implement this function with vectorized computations.                  #\n",
    "    #       Try to write the values in the form of matrix multiplication.          #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's test your implementation of `values_without_for_loop`. You should get a small value as the output. Ours is of the order of 1e-13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def test_values_without_for_loop():\n",
    "    X = np.random.randn(20, 25)\n",
    "    Y = np.random.randn(30, 25)\n",
    "    \n",
    "    out_correct = values_with_for_loop(X, Y)\n",
    "    out = values_without_for_loop(X, Y)\n",
    "    \n",
    "    print(np.linalg.norm(out - out_correct))\n",
    "    \n",
    "test_values_without_for_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, let's compare the running time of functions! We have provided the following code snippet to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(1000, 150)\n",
    "b = np.random.randn(800, 150)\n",
    "\n",
    "tic = time.time()\n",
    "values_with_for_loop(a, b)\n",
    "toc = time.time()\n",
    "print('Running time of values with for loop:', toc - tic, 'seconds')\n",
    "\n",
    "tic = time.time()\n",
    "values_without_for_loop(a, b)\n",
    "toc = time.time()\n",
    "print('Running time of values without for loop:', toc - tic, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You should see a huge improvement in runnnig time of `values_without_for_loop` compared to `values_with_for_loop`. This experiment shows how vectorized and matrix computations in Numpy could be much more effiecient than just naively using for loops in Python. Numpy is a powerful module with a beautiful functional API and many of its functions are implemented in C which results in a great efficiency. Nevertheless, one of the biggest disadvantages of Numpy is that it cannot run on GPU. By using deep learning frameworks such as TensorFlow, PyTorch, Keras, and ... we will sidestep this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Problem 3. Jacobian (10pts)\n",
    "We have provided the function `func` for you below. You have to find out the operations done by this function and then complete the code of `jacobian_func` to compute the jacobian of the output of `func` (i.e. x_4). Note that the Jacobian of a function $\\mathbf{f}$: $\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ is an $m \\times n$ matrix defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"image/jacobian.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Note:** Write down the computations on a paper and take the derivatives manually. Then, implement `jacobian_func` using Numpy. <br/>\n",
    "Approximating the gradients using numerical methods DOES NOT get any points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    \"\"\"\n",
    "    x: input vector as a numpy 1d-array.\n",
    "    \"\"\"\n",
    "    x1 = x - np.ones_like(x)\n",
    "    x2 = x1 ** 2\n",
    "    x3 = np.empty_like(x2)\n",
    "\n",
    "    for i in range(len(x3)-1):\n",
    "        x3[i] = x2[i] * np.exp(x2[i+1])\n",
    "    \n",
    "    x4 = x3[::2].copy()\n",
    "    \n",
    "    return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def jacobian_func(x):\n",
    "    \"\"\"\n",
    "    x is the same input passed to func on which the computations are done.\n",
    "    you have to return the jacobian of the output of func.\n",
    "    \"\"\"\n",
    "    ################################################################################\n",
    "    # TODO: consider func and its output x_4 and compute its jacobian.             #\n",
    "    # x is the same input we pass to func.                                         #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Problem 4. Preprocessing (12pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 4.1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Fashion-MNIST is a dataset of Zalando’s article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28×28 grayscale image, associated with a label from 10 classes. Fashion-MNIST is intended to serve as a direct drop-in replacement of the original MNIST dataset for benchmarking machine learning algorithms.<br/> \n",
    "We have provided this dataset saved in some files under the `data` directory for you.  Training data has been saved in 5 files (`train1.npy`, ..., `train5.npy`) and test data file is `test.npy`. Labels are also stored in two files `labels_train` and `labels_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(root_path):\n",
    "    \"\"\"\n",
    "    root_path: the root directory of data files.\n",
    "    outputs:\n",
    "    1) test_data: test data which is a numpy array of shape (10000, 784).\n",
    "    2) train_data_array: a Python list containing 5 numpy 2d-arrays each one of them has the shape (12000, 784).\n",
    "    3) test_labels: a numpy array with shape (10000, ) containing the labels (0 to 9) of the test set images.\n",
    "    4) train_labels: a numpy array with shape (60000, ) containing the labels (0 to 9) of the training set images.\n",
    "    \"\"\"\n",
    "    train_data_file_names = ['train{}.npy'.format(x) for x in range(1, 6)]\n",
    "    test_data_file_name = 'test.npy'\n",
    "    test_labels_file_name = 'labels_test.npy'\n",
    "    train_labels_file_name = 'labels_train.npy'\n",
    "    \n",
    "    train_data_list = []\n",
    "    for file_name in train_data_file_names:\n",
    "        file_path = os.path.join(root_path, file_name)\n",
    "        ################################################################################\n",
    "        # TODO: provided the file path, load the train data in the form of numpy array #\n",
    "        # and append it to the end of train_data_list.                                 #\n",
    "        ################################################################################\n",
    "        pass\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "    \n",
    "    ################################################################################\n",
    "    # TODO: load the test data, test labels and train labels in the form of numpy  #\n",
    "    # arrays as well and save them in test_data, test_labels and train_labels.     #                                                              #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    \n",
    "    return test_data, train_data_list, test_labels, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's test your implementation of `load_data` with the following function. You have to get no erros after running this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def test_load_data(root_path):\n",
    "    test_data, train_data_list, test_labels, train_labels = load_data('data')\n",
    "    assert test_data.shape == (10000, 784)\n",
    "    assert len(train_data_list) == 5\n",
    "    assert test_labels.shape == (10000, )\n",
    "    assert train_labels.shape == (60000, )\n",
    "    assert train_data_list[0].shape == (12000, 784)\n",
    "    print('You have successfully loaded the data!')\n",
    "    \n",
    "test_load_data('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Each one of the samples of Fashion-MNIST dataset is a $28\\times28$ graysacle image. Pixel values are between 0 and 255. Here is an image of a t-shirt in the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<img src=\"image/mnist.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 4.2. Concatenation\n",
    "You have loaded the training data as a list of five numpy arrays, each one of them has the shape $(12000, 784)$. We need to concatenate these five arrays into one array with shape $(60000, 784)$. <br/> \n",
    "In this part you should Implement a function for cancatenating a set of numpy nd-arrays given to you in a Python list (Note that the list does not necessarily contain five arrays and the arrays might not be 2d-arrays! You have to implement the function for general case). You have to do the concatenation along the first dimension i.e. axis=0. You are **not** allowed to use `np.concatenate`, `np.hstack`, and `np.vstack` in your code and you have to do it from scratch using Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def concat(list_of_arrays):\n",
    "    \"\"\"\n",
    "    list_of_arrays is a non-empty list of numpy arrays (with arbitrary number of dimensions) with the SAME shape\n",
    "    output: array_concat which is a numpy ndarray\n",
    "    \"\"\"\n",
    "    array_concat = None\n",
    "    ################################################################################\n",
    "    # TODO: you have to concatenate the numpy arrays along the first axis into one #\n",
    "    # single numpy array called array_concat.                                      #\n",
    "    # You are not allowed to use np.concatenate, np.hsatck, and np.vstack          #\n",
    "    # in your implementation.                                                      #\n",
    "    # for example if list_of_arrays is [arr1, arr2] and                            #\n",
    "    # arr1: [[1, 1, 1], [1, 1, 1]] (shape: (2, 3))                                 #\n",
    "    # arr2: [[2, 2, 2], [2, 2, 2]] (shape: (2, 3))                                 #\n",
    "    # you have to return                                                           #\n",
    "    # output: [[1, 1, 1], [1, 1, 1], [2, 2, 2], [2, 2, 2]] (shape: (4,3))          #\n",
    "    # In fact, you have to implement the function np.cancatenate() from scratch    #\n",
    "    # by yourself.                                                                 #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return array_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's test your implementation with the following function. You have to get no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def test_concat():\n",
    "    t1 = [np.random.randn(10) for _ in range(10)]\n",
    "    t2 = [np.random.randn(5, 3) for _ in range(5)]\n",
    "    t3 = [np.random.randn(1, 5, 3, 4) for _ in range(3)]\n",
    "    t3 = [np.random.randn(100, 5, 2, 5, 14) for _ in range(3)]\n",
    "    t1_concat, t2_concat, t3_concat = concat(t1), concat(t2), concat(t3)\n",
    "    assert np.array_equal(t1_concat, np.concatenate(t1, axis=0))\n",
    "    assert np.array_equal(t2_concat, np.concatenate(t2, axis=0))\n",
    "    assert np.array_equal(t3_concat, np.concatenate(t3, axis=0))\n",
    "    print('you have successfully implemented concatenation!')\n",
    "\n",
    "test_concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's concat `train_data_list` with your `concat` function and save it in `train_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_data, train_data_list, test_labels, train_labels = load_data('data')\n",
    "train_data = concat(train_data_list)\n",
    "assert train_data.shape == (60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next step is visualizing some of the images we have loaded. But, first we have to reshape each sample into a 2d-array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 4.3. Reshape\n",
    "Complete the function `reshape` to reshape a flat array with shape $(N, d^2)$ to an array with shape $(N, d, d)$. You can use `np.reshape` in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def reshape(x):\n",
    "    \"\"\"\n",
    "    x is an array with shape (N, d*d)\n",
    "    output: x_reshaped which is numpy 3d-array with shape (N, d, d)\n",
    "    \"\"\"\n",
    "    x_reshaped = None\n",
    "    ################################################################################\n",
    "    # TODO: You have to reshape the input x which has the shape (N, d^2) to an     #\n",
    "    # array with shape (N, d, d) and save it in x_reshaped.                        #                                          \n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return x_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's test you implementation of `reshape` with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def test_reshape():\n",
    "    a = np.empty([531, 100])\n",
    "    b = np.empty([3000, 4096])\n",
    "    c = np.empty([10000, 10000])\n",
    "    a_reshaped, b_reshaped, c_reshaped = reshape(a), reshape(b), reshape(c) \n",
    "    assert a_reshaped.shape == (531, 10, 10)\n",
    "    assert b_reshaped.shape == (3000, 64, 64)\n",
    "    assert c_reshaped.shape == (10000, 100, 100)\n",
    "    print('you have successfully implemented reshape!')\n",
    "    \n",
    "test_reshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 4.4. Visualization\n",
    "Let's apply your reshape function on some of the samples in the dataset and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "samples_per_class = 7\n",
    "\n",
    "for i in range(10):\n",
    "    idxs = np.where(train_labels==i)[0]\n",
    "    idxs = idxs[:samples_per_class]\n",
    "    sample_imgs = reshape(train_data[idxs])\n",
    "    \n",
    "    for j, idx in enumerate(idxs):\n",
    "        plt_idx = i * samples_per_class + j + 1\n",
    "        plt.subplot(10, samples_per_class, plt_idx)\n",
    "        plt.imshow(sample_imgs[j])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 4.5. Split\n",
    "During this course, you will see that we mostly partition our training data into train and validation set. Implement the following function to split the given data into two sets provided the ratio between the size of validation set and the whole training dataset. You **cannot** use `np.array_split()` or `np.split()` in the first function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def split_train_1(x, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    x: a numpy ndarray\n",
    "    val_ratio: ratio between the size of validation set and x\n",
    "    ouputs: x_train, x_val: numpy ndarrays\n",
    "    \"\"\"\n",
    "    x_train, x_val = None, None\n",
    "    #################################################################################\n",
    "    # TODO: split the input x (numpy ndarray) into two sets x_train and x_val given #\n",
    "    # the ratio between the number of the elements in the validation set (x_val)    # \n",
    "    # and the number of elements in x (e.g. if val_ratio=0.2 and                    #\n",
    "    # x's shape is (1000, 2, 3, 5) then x_train's shape would be (800, 2, 3, 5)     #\n",
    "    # and x_val's shape would be (200, 2, 3, 5)). Note that if N is                 #\n",
    "    # the number of instances in x then N * (1 - val_ratio) first instances would   #\n",
    "    # be x_train and the last N * val_ratio instances would be x_val.               #\n",
    "    # you cannot use np.split or np.array_split in your implementation.             #                    \n",
    "    #################################################################################\n",
    "    pass\n",
    "    #################################################################################\n",
    "    #                                 END OF YOUR CODE                              #\n",
    "    #################################################################################\n",
    "    return x_train, x_val\n",
    "\n",
    "def split_train_2(x, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    x: a numpy ndarray\n",
    "    ratio: ratio between the size of validation set and size of input x\n",
    "    ouputs: x_train, x_val: numpy ndarrays\n",
    "    \"\"\"\n",
    "    #################################################################################\n",
    "    # TODO: implement the above function with np.split.                             #                \n",
    "    #################################################################################\n",
    "    pass\n",
    "    #################################################################################\n",
    "    #                                 END OF YOUR CODE                              #\n",
    "    #################################################################################\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 4.6. Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Shuffling data serves the purpose of making sure that models remain general and overfit less. You will want to shuffle the data to make sure that the training/test/validation sets are representative of the overall distribution of the data.<br/>\n",
    "Consider the function `shuffle` which takes two parameters: \n",
    "1. $x$ which is a numpy nd-array with shape $(N, d1, d2, ...)$ \n",
    "2. $y$ which is a numpy 1d-array with shape $(N, )$.\n",
    "\n",
    "You have to complete this function so that it shuffles x and y with the **same** order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    \"\"\"\n",
    "    x: a numpy nd-array with shape (N, d1, d2, ...)\n",
    "    y: a numpy 1d-array with shape (N, )\n",
    "    output: x_shuffled and y_shuffled\n",
    "    \"\"\"\n",
    "    x_shuffled, y_shuffled = None, None\n",
    "    ################################################################################\n",
    "    # TODO: You have to shuffle x and y with the                                   #\n",
    "    # same order. for example if x is [[1, 1, 1], [2, 2, 2], [3, 3, 3]]            #\n",
    "    # and y is [1, 2, 3] then a valid shuffling would be                           #\n",
    "    # x_shuffled: [[3, 3, 3], [1, 1, 1], [2, 2, 2]]                                #\n",
    "    # y_shuffled: [3, 1, 2]                                                        #\n",
    "    # Note that the only condition you have to satisfy is that the order of        #\n",
    "    # shuffling for both x and y should be the same and there is no other          #\n",
    "    # limitation on the order. Therefore there may be more than one valid          #\n",
    "    # shuffling.                                                                   #\n",
    "    # you can use np.random.shuffle() for shuffling.                               #                                                    #                                          \n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return x_shuffled, y_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Make sure that your implementation is correct with the following simple test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def test_shuffle():\n",
    "    x = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    y = np.array([1, 2, 3])\n",
    "    x_shuffled, y_shuffled = shuffle(x, y)\n",
    "    print(x_shuffled)\n",
    "    print(y_shuffled)\n",
    "\n",
    "test_shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Problem 5. Linear Multi-Class SVM with Soft-Margin (18pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements.\n",
    "\n",
    "There are several ways to define a loss function for multi-class SVM. In this problem, the following loss function will be used for training the multi-class SVM (Please take a look at p. 46 of the ML Review slides):\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "J(W) = \\frac{1}{N} \\sum_{i=1}^{N}{L^{(i)}} + \\lambda ||W||^2\\\\\n",
    "\\large\n",
    "L^{(i)} = \\sum_{j \\neq y^{(i)}}^{}{max(0, 1 + s_j - s_{y^{(i)}})} = \\sum_{j \\neq y^{(i)}}^{}{max(0, 1 + w_j^T x^{(i)} - w_{y^{(i)}}^T x^{(i)})}\n",
    "\\;\\\\\n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, let's use the functions of the previous problem to preprocess the data and make 4 sets `X_train`, `X_val`, `y_train`, `y_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "test_data, train_data_list, test_labels, train_labels = load_data('data')\n",
    "train_data = concat(train_data_list)\n",
    "\n",
    "print(train_data.shape)  # Expected ouput: (60000, 784)\n",
    "print(test_data.shape)  # Expected ouput: (10000, 784)\n",
    "print(test_labels.shape)  # Expected ouput: (10000,)\n",
    "print(train_labels.shape)  # Expected ouput: (60000,)\n",
    "\n",
    "train_data_shuffled, train_labels_shuffled = shuffle(train_data, train_labels)\n",
    "X_test, y_test = test_data, test_labels\n",
    "X_train, X_val = split_train_1(train_data, val_ratio=1/60)\n",
    "print(X_train.shape, X_val.shape)  # Expected ouput: (59000, 784) (1000, 784)\n",
    "y_train, y_val = split_train_1(train_labels, val_ratio=1/60)\n",
    "print(y_train.shape, y_val.shape)  # Expected ouput: (59000,) (1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# >>>>>WARNING: RUN THIS CELL ONLY ONCE!<<<<<\n",
    "\n",
    "# adding 1s to the end of feature vectors to be multiplied by bias term of weights\n",
    "X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "print(X_train.shape)  # Expected ouput: (59000, 785)\n",
    "print(X_val.shape)  # Expected ouput: (1000, 785)\n",
    "print(X_test.shape)  # Expected ouput: (10000, 785)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Open `svm.py` and complete the code of the linear svm model in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's check your implementations first:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's first check if your model computes the hinge loss correctly. You should witness a small values as the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "toy_model = SVM(n_features=10, n_classes=5, std=0.01)\n",
    "x = np.random.rand(20, 10)\n",
    "y = np.random.randint(0, 5, 20)\n",
    "correct_loss = 3.999079560852596\n",
    "loss = toy_model.loss(x, y, 0.25)\n",
    "\n",
    "print('relative error of loss:', abs(loss - correct_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's check if the gradients are computed correctly. You should get a small value as the error. Ours is of the order of 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# >>>>>WARNING: RUN THIS CELL ONLY ONCE AFTER YOU RAN THE ABOVE CELL!<<<<<\n",
    "\n",
    "gradient = toy_model.update_weights(learning_rate=1e-2)\n",
    "correct_gradient = [[-0.24790043, -0.02616584,  0.0862217,  -0.066655,    0.25564707],\n",
    "                    [-0.02056357,  0.05417903, -0.05449371, -0.07649293,  0.09846397],\n",
    "                    [-0.01443777, -0.14332005, -0.00198323, -0.23687162,  0.39444998],\n",
    "                    [-0.09852023,  0.03344655,  0.00652346, -0.15866452,  0.21542415],\n",
    "                    [-0.2999338,  -0.04307378,  0.34938565, -0.32666563,  0.3199567 ],\n",
    "                    [-0.1263978,   0.13268628,  0.15897914, -0.16465115, -0.00139483],\n",
    "                    [-0.00084713, -0.17737171,  0.05615944,  0.03299787,  0.08956249],\n",
    "                    [-0.1513251,  -0.05118482,  0.16787481, -0.12316938,  0.155753  ],\n",
    "                    [-0.13682534,  0.14630157,  0.02634592, -0.10531288,  0.06899802],\n",
    "                    [-0.13455525, -0.04130863,  0.11486015, -0.06620673,  0.12643906]]\n",
    "\n",
    "assert gradient.shape == toy_model.W.shape\n",
    "print('relative error of gradient:', np.linalg.norm(gradient - correct_gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's train the main model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from svm import SVM\n",
    "model = SVM(n_features=785, n_classes=10, std=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now let's train your model on the training set. Meanwhile, you have to witness that the printed loss drops significantly and the accuracy on validation set increases. Our loss and accuracy will reach values close to 1.0 and 79% respectively at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "\n",
    "num_iters, batch_size = 1000, 200\n",
    "\n",
    "for it in range(num_iters):\n",
    "    X_batch, y_batch = None, None\n",
    "    ################################################################################\n",
    "    # TODO: Sample batch_size elements from the training data and their            #\n",
    "    # corresponding labels to use in this round of gradient descent.               #\n",
    "    # Store the data in X_batch and their corresponding labels in                  #\n",
    "    # y_batch; after sampling X_batch should have shape (batch_size, n_features)   #\n",
    "    # and y_batch should have shape (batch_size,)                                  #\n",
    "    #                                                                              #\n",
    "    # Hint: Use np.random.choice to generate indices. Sampling with                #\n",
    "    # replacement is faster than sampling without replacement.                     #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    \n",
    "    loss = model.loss(X_batch, y_batch, 2.5e4)\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        val_preds =  model.predict(X_val)\n",
    "        val_res = val_preds == y_val\n",
    "        test_acc = np.sum(val_res) / len(val_res)\n",
    "        print('iteration %d, loss %f, val acc %.2f%%' % (it, loss, 100*test_acc))\n",
    "    \n",
    "    model.update_weights(learning_rate=1e-7)\n",
    "    loss_history.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's plot the training loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.ylabel('training loss')\n",
    "plt.xlabel('iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally let's test your model on the test set. We get an accuracy above 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "predictions =  model.predict(X_test)\n",
    "test_res = predictions == y_test\n",
    "test_acc = np.sum(test_res) / len(test_res)\n",
    "print(\"accuracy on test set: %.2f%%\" % (100*test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
